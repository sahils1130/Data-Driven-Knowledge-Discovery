---
title: "ii.Exercise3.7.9"
author: "Kaarthik Sundaramoorthy, Sahil Shah and Vidhi Shah"
date: "6/3/2020"
output: 
  pdf_document:
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This question involves the use of **multiple linear regression** on the
**Auto** data set.

```{r data}
require(ISLR)
data(Auto)
attach(Auto)
```

(a) Produce a **scatterplot** matrix which includes all of the variables
in the data set.

```{r parta}
par(mfrow = c(1,1))
pairs(Auto)
```

(b) Compute the matrix of correlations between the variables using
the function `cor()`. You will need to exclude the name variable,
`cor()` which is qualitative.

```{r partb}
head(Auto)
##help("cor")
cor(subset(Auto, select = -name))
```

(c) Use the `lm()` function to perform a multiple linear regression
with mpg as the response and all other variables except name as
the predictors. Use the `summary()` function to print the results.
Comment on the output. For instance:

```{r partc0}
fit.lm <- lm(mpg ~ . -name , data = Auto )
summary(fit.lm)
```

(c) i. Is there a relationship between the predictors and the response?

Ans. Yes, there is a relationship between the predictors and the response variables. The F-Statistics is really far from 1, which results into small p-value. Indicating that there is an evidence against the null hypothesis.

(c) ii. Which predictors appear to have a statistically significant
relationship to the response?

Ans. Predictors like `origin`, `year`, `weight` and `displacement` have the statistically significant relationship with the response variable.

(c) iii. What does the coefficient for the year variable suggest?

Ans. The coefficient for the `year` i.e. 0.75 with the additional year of the car's age, the `mpg` will on average increase by 0.75. In other words it suggests that later model year car will have better `mpg`.

(d) Use the `plot()` function to produce diagnostic plots of the linear
regression fit. Comment on any problems you see with the fit.
Do the residual plots suggest any unusually large outliers? Does
the leverage plot identify any observations with unusually high
leverage?

```{r partd}
par(mfrow = c(2,2))
plot(fit.lm)
```

Ans. There is an evidence of the non-linearity. The polt of Residuals vs Fitted shows that variance of the error terms increase with the values of the response. The Residuals vs Leverage plot shows no outliers, but the tending of the curve at point 14 shows the sign of high leverage.

(e) Use the `*` and `:` symbols to fit linear regression models with
interaction effects. Do any interactions appear to be statistically
significant?

```{r parte}
lm.fit1 <- lm(mpg ~ .-name + cylinders:horsepower, data = Auto)
lm.fit2 <- lm(mpg~displacement+origin+year*weight, data = Auto)
lm.fit3 <- lm(mpg~year+origin+displacement*weight, data = Auto)
lm.fit4 <- lm(mpg~cylinders*displacement+displacement*weight, data = Auto)
summary(lm.fit1)
summary(lm.fit2)
summary(lm.fit3)
summary(lm.fit4)
```

Ans. As seen in question (c) part (ii) there are **4** variables that are statistically significant, We are try the significant interactions. There is statistic significance in four of the lm.fit. There is a high correlated pairs in the lm.fit4 looking at the p-value, there is a strong statistical significance between displacement and weight, and there is none between cylinders and displacement.

(f) Try a few different transformations of the variables, such as
log(X), âˆšX, X2. Comment on your findings.

```{r partf}

```